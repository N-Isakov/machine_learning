{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iY8ZckurbViY",
    "colab_type": "text"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Sentiment analysis is a key NLP task that receives much attention last years. Detecting sentiment of a text can be important for many applications, for instance, getting customer feedback about a brand or product, aggregating and summarising opinions in reviews for recommender systems and so on.\n",
    "\n",
    "Sentiment analysis can be viewed as a text classification problem with opinions and emotions in the text as the criterion of the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuaTJbAUm3N3",
    "colab_type": "text"
   },
   "source": [
    "### Goal\n",
    "\n",
    "The goal is to configure and train the neural network and logistic regression on the Twitter data to make predictions opinion polarity using google colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0k_SbnMXZlU",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "### Requirements:\n",
    "- tensorflow\n",
    "- keras\n",
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnI3_PFpZ7NW",
    "colab_type": "text"
   },
   "source": [
    "### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BndMjiHIZg41",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, concatenate, Activation, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDnISB0zMwEg",
    "colab_type": "text"
   },
   "source": [
    "### DATASET:\n",
    "\n",
    "A typical sentiment analysis system needs an annotated text\n",
    "corpus on which the system is trained and/or evaluated.\n",
    "In the English language, resources with annotated texts are\n",
    "widely available, however, in Russian only a few such resources are available.\n",
    "\n",
    "\n",
    "I choosed  http://study.mokoron.com/ - Twitter messages in Russian, labeled (positive or negative) mannualy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JBiMRJ3hYjp8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "6b14404e-3086-4219-9602-08f51dd2373d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative.csv  positive.csv\n"
     ]
    }
   ],
   "source": [
    "! mkdir data\n",
    "! wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv -P data -q\n",
    "! wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv -P data -q\n",
    "! ls data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Ymk-0V26a2tw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# TODO: Translate comments to Russian\n",
    "column_list = [\n",
    "    \"id\", # уникальный номер сообщения в системе twitter;\n",
    "    \"tdate\", # дата публикации сообщения (твита);\n",
    "    \"tmane\", # имя пользователя, опубликовавшего сообщение;\n",
    "    \"ttext\", # текст сообщения (твита);\n",
    "    \"ttype\", # поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);\n",
    "    \"trep\", # количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "    \"tfav\", # число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "    \"tstcount\", # число всех сообщений пользователя в сети twitter;\n",
    "    \"tfol\", # количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "    \"tfrien\", # количество друзей пользователя (те люди, которых читает пользователь);\n",
    "    \"listcount\" # количество листов-подписок в которые добавлен твиттер-пользователь.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LGMy9EnlZdE9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206.0
    },
    "outputId": "85ed9efb-695c-4634-8045-4e58ee6ad5bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tmane  \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                               ttext  ttype  trep  tfav  \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...      1     0     0   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...      1     0     0   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...      1     0     1   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...      1     0     1   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...      1     0     0   \n",
       "\n",
       "   tstcount   tfol  tfrien  listcount  \n",
       "0         0   7569      62         61  \n",
       "1         0  11825      59         31  \n",
       "2         0   1273      26         27  \n",
       "3         0   1549      19         17  \n",
       "4         0    597      16         23  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_positive = pd.read_csv(\"data/positive.csv\", sep=\";\", names=column_list, index_col=False) \n",
    "data_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e-dC2Ek4ydFt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "b635751f-1b4f-44fb-a7c2-4c9e8ae2dd18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Olgana1000000 нет...предупреждает, что их власть надолго...но думаю опять переоценил он свои возможности..алкоголь не даст дожить до 70))'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_positive[\"ttext\"][777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VCMhi5I4dqX-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "ef62d1d7-dcd3-448d-f3b6-15a8b0e40521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114911, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ux_nvNS5dfZD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206.0
    },
    "outputId": "757650b9-a26e-45ae-f670-589fc71a774e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906762813579264</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906818262687744</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906858515398656</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906914437685248</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906914723295232</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tmane  \\\n",
       "0  408906762813579264  1386325944  dugarchikbellko   \n",
       "1  408906818262687744  1386325957     nugemycejela   \n",
       "2  408906858515398656  1386325966          4post21   \n",
       "3  408906914437685248  1386325980         Poliwake   \n",
       "4  408906914723295232  1386325980       capyvixowe   \n",
       "\n",
       "                                               ttext  ttype  trep  tfav  \\\n",
       "0  на работе был полный пиддес :| и так каждое за...     -1     0     0   \n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...     -1     0     0   \n",
       "2  @elina_4post как говорят обещаного три года жд...     -1     0     0   \n",
       "3  Желаю хорошего полёта и удачной посадки,я буду...     -1     0     0   \n",
       "4  Обновил за каким-то лешим surf, теперь не рабо...     -1     0     0   \n",
       "\n",
       "   tstcount   tfol  tfrien  listcount  \n",
       "0         0   8064     111         94  \n",
       "1         0     26      42         39  \n",
       "2         0    718      49        249  \n",
       "3         0  10628     207        200  \n",
       "4         0     35      17         34  "
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_negative = pd.read_csv(\"data/negative.csv\", sep=\";\", names=column_list, index_col=False) \n",
    "data_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZXUDMABidvu2",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "def6f492-48a1-41d7-b0d2-dfa38fcb8175"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111923, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hqcKHRifd4qP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "ecc82e77-4a86-4d59-be10-a950857c76ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226834, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge positive and negative tweets into one df\n",
    "data_input = shuffle(pd.concat([data_positive, data_negative], ignore_index=True))\n",
    "data_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSp6OtvgfWHq",
    "colab_type": "text"
   },
   "source": [
    "### Data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ESIWBmMLfYT9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Constants for data processing:\n",
    "RANDOM_STATE = 42\n",
    "VOCABULARY_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_SIZE = 200\n",
    "TEST_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "57vk9i-Om2eS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tpT9m1YovmG1",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Convert words to lower case\n",
    "# TODO: clean data: delete names, urls and others\n",
    "text = data_input[\"ttext\"].str.lower()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mZu3cCqDfUYQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# target value, 1-positive, 0-negative\n",
    "y = pd.to_numeric((data_input[\"ttype\"] + 1) / 2, downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "D3XW5CCDfCjv",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Split on test/val and train datasets\n",
    "# TODO: Use cross-validation\n",
    "text_train, text_val, y_train, y_val = train_test_split(text, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sb-RO4DlkXza",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "outputId": "93221b58-146d-4414-e5ad-35583e75ce22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 158783 entries with 49.37% negative, 50.63% positive\n",
      "Test/Val set has total 68051 entries with 49.26% negative, 50.74% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set has total {cnt_rows} entries with {neg_rate:.2%} negative, {pos_rate:.2%} positive\".format(cnt_rows=text_train.shape[0], neg_rate=1-np.average(y_train), pos_rate=np.average(y_train)))\n",
    "print(\"Test/Val set has total {cnt_rows} entries with {neg_rate:.2%} negative, {pos_rate:.2%} positive\".format(cnt_rows=text_val.shape[0], neg_rate=1-np.average(y_val), pos_rate=np.average(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "netNGT6TmU-8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Create sequences for our neural network\n",
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_val)\n",
    "\n",
    "# TODO: Compare results for padding='post' and padding='pre'\n",
    "sequences_pad_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "sequences_pad_val = pad_sequences(sequences_val, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H-RJm7IbvqqC",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164.0
    },
    "outputId": "4587556a-ee93-454a-982e-56e482e0bbcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  15, 249,   4,  17,  29, 103,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_pad_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "v5YM40ljixZ4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Create train and test/val data for logistic regression: \n",
    "vectorizer = TfidfVectorizer(max_features=VOCABULARY_SIZE, ngram_range=(1, 3))\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train_tfidf = vectorizer.transform(text_train)\n",
    "X_val_tfidf = vectorizer.transform(text_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgT3fGu23h9h",
    "colab_type": "text"
   },
   "source": [
    "### Models:\n",
    "#### 1. CNN\n",
    "\n",
    "Model based on Y. Kim's famous paper \"Convolutional Neural Networks for Sentence Classification\". https://arxiv.org/pdf/1408.5882.pdf. In this analysis, I will not use multi-channel approach (eg. one channel for static input word vectors, another channel for word vectors input but set them to update during training), only different n-grams.\n",
    "\n",
    "The model has parallel layers which take the same input but do their own computation, then the results will be merged. In this kind of neural network structure, we can use Kera functional API. https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nuyIQMNhPaPd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Constants for CNN model:\n",
    "NUMBER_OF_FILTERS = 100\n",
    "DROPOUT_RATE = 0.5      \n",
    "BATCH_SIZE = 50      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "B067pATD2AIm",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660.0
    },
    "outputId": "180baed8-4d94-4f3b-e4bb-86237dda65bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 200)     2000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 99, 100)      40100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 100)      80100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 96, 100)      100100      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,297,613\n",
      "Trainable params: 2,297,613\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specify each convolution layer and their kernel siz i.e. n-grams\n",
    "# TODO: Try to add dropout layer after each conv layer\n",
    "# TODO: Batch BatchNormalization?\n",
    "# TODO: use pre-trained word embeddings\n",
    "  \n",
    "cnn_model_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "cnn_model_embedding = Embedding(VOCABULARY_SIZE, EMBEDDING_SIZE, input_length=MAX_SEQUENCE_LENGTH, trainable=True)(cnn_model_input)\n",
    "\n",
    "cnn_model_branch_2_conv1 = Conv1D(filters=NUMBER_OF_FILTERS, kernel_size=2, padding='valid', activation='relu', strides=1)(cnn_model_embedding)\n",
    "cnn_model_branch_2_maxpool = GlobalMaxPooling1D()(cnn_model_branch_2_conv1)\n",
    "\n",
    "cnn_model_branch_4_conv1 = Conv1D(filters=NUMBER_OF_FILTERS, kernel_size=4, padding='valid', activation='relu', strides=1)(cnn_model_embedding)\n",
    "cnn_model_branch_4_maxpool = GlobalMaxPooling1D()(cnn_model_branch_4_conv1)\n",
    "\n",
    "cnn_model_branch_5_conv1 = Conv1D(filters=NUMBER_OF_FILTERS, kernel_size=5, padding='valid', activation='relu', strides=1)(cnn_model_embedding)\n",
    "cnn_model_branch_5_maxpool = GlobalMaxPooling1D()(cnn_model_branch_5_conv1)\n",
    "\n",
    "cnn_model_concatenate = concatenate([cnn_model_branch_2_maxpool, cnn_model_branch_4_maxpool, cnn_model_branch_5_maxpool], axis=1)\n",
    "\n",
    "cnn_model_dense_1 = Dense(256, activation='relu')(cnn_model_concatenate)\n",
    "cnn_model_dropout = Dropout(DROPOUT_RATE)(cnn_model_dense_1)\n",
    "cnn_model_dense_2 = Dense(1)(cnn_model_dropout)\n",
    "cnn_model_output = Activation('sigmoid')(cnn_model_dense_2)\n",
    "cnn_model = Model(inputs=[cnn_model_input], outputs=[cnn_model_output])\n",
    "\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc4Uo7g7XJyT",
    "colab_type": "text"
   },
   "source": [
    "#### FIT CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UI0Vr2VfdcB6",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "ee5fe9fd-62c8-47d1-d176-b370c1499046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  sample_data\n"
     ]
    }
   ],
   "source": [
    "! mkdir models\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "yEJ5On3KXuUZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "MODEL_FILEPATH = \"models/CNN_best_weights.{epoch:02d}-{val_acc:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-bdXP5RaXMa8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311.0
    },
    "outputId": "e9e189ca-9f61-4353-a210-4e560ababb57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 12.4 µs\n",
      "Train on 111148 samples, validate on 47635 samples\n",
      "Epoch 1/3\n",
      "111148/111148 [==============================] - 685s 6ms/step - loss: 0.5004 - acc: 0.7447 - val_loss: 0.4633 - val_acc: 0.7713\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77130, saving model to models/CNN_best_weights.01-0.7713.hdf5\n",
      "Epoch 2/3\n",
      "111148/111148 [==============================] - 681s 6ms/step - loss: 0.3894 - acc: 0.8189 - val_loss: 0.4774 - val_acc: 0.7713\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.77130\n",
      "Epoch 3/3\n",
      "111148/111148 [==============================] - 685s 6ms/step - loss: 0.2550 - acc: 0.8899 - val_loss: 0.5758 - val_acc: 0.7590\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbca122f2b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(MODEL_FILEPATH, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "%time\n",
    "cnn_model.fit(sequences_pad_train, y_train, batch_size=BATCH_SIZE, epochs=3, validation_split=0.3, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EGeqPlFiDEbm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Download best weights\n",
    "files.download(\"models/CNN_best_weights.01-0.7713.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kbtL28Jv7cBQ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "outputId": "8d50a5d1-2621-4593-c664-1b3b9c2849a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ad3e8d4369b0e8cad21581f9f9ebdd3b7135299999cc8de311f327943c542ef  models/CNN_best_weights.01-0.7713.hdf5\n",
      "27M\tmodels/CNN_best_weights.01-0.7713.hdf5\n"
     ]
    }
   ],
   "source": [
    "! sha256sum models/CNN_best_weights.01-0.7713.hdf5\n",
    "! du -sh models/CNN_best_weights.01-0.7713.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iFxB6uA1p71f",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Download model\n",
    "with open(\"models/cnn_model.json\", \"w\") as json_file:\n",
    "  json_file.write(cnn_model.to_json())\n",
    "files.download(\"models/cnn_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "G4qX7IUTr3yJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "outputId": "b5317656-a9b7-48f1-a14f-4b604f80ad08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8a3c8edb7f6956b5455d07b0db787549a11b6974f06c0ec33b4cfa5d4d212c58  models/cnn_model.json\n",
      "8.0K\tmodels/cnn_model.json\n"
     ]
    }
   ],
   "source": [
    "! sha256sum models/cnn_model.json\n",
    "! du -sh models/cnn_model.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6iWUjAasUW3",
    "colab_type": "text"
   },
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8u-i4MhTnApR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "965522f4-9fe0-48e6-aa83-f4fd590f102d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_best_weights.01-0.7713.hdf5  cnn_model.json\n"
     ]
    }
   ],
   "source": [
    "# Weights and model can be downloaded from url:\n",
    "! mkdir model_loaded\n",
    "! wget https://www.dropbox.com/s/xkb69ivurvepk39/CNN_best_weights.01-0.7713.hdf5 -P model_loaded -q\n",
    "! wget https://www.dropbox.com/s/g55ezivfssvvgwv/cnn_model.json -P model_loaded -q\n",
    "! ls model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WxqYsnedoBzO",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660.0
    },
    "outputId": "ce4b81ba-d36d-49d9-eefd-fa2f719c0126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 200)     2000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 99, 100)      40100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 100)      80100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 96, 100)      100100      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,297,613\n",
      "Trainable params: 2,297,613\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('model_loaded/cnn_model.json', 'r') as json_file:\n",
    "  cnn_model_loaded = model_from_json(json_file.read())\n",
    "\n",
    "cnn_model_loaded.load_weights(\"model_loaded/CNN_best_weights.01-0.7713.hdf5\") \n",
    "cnn_model_loaded.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "cnn_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tM-dAz7obf4m",
    "colab_type": "text"
   },
   "source": [
    "#### 2. Logistic regression + Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "WOflA81ub-vb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127.0
    },
    "outputId": "f2775b51-0986-42e1-df3b-e50317b560d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple logistic regression\n",
    "# TODO: Tune hyper-parameters\n",
    "\n",
    "%time\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgwW9-r34u4l",
    "colab_type": "text"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "CLMnk-x_Yea6",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72.0
    },
    "outputId": "226f0f97-91f3-456e-d58c-0eb7d94394c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68051/68051 [==============================] - 81s 1ms/step\n",
      "CNN accuracy: 0.77\n",
      "LR accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_cnn = cnn_model_loaded.evaluate(sequences_pad_val, y_val,batch_size=BATCH_SIZE, verbose=1)[1]\n",
    "accuracy_lr = lr_model.score(X_val_tfidf, y_val)\n",
    "print(\"CNN accuracy: {0:.2f}\\nLR accuracy: {1:.2f}\".format(accuracy_cnn, accuracy_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "t4Pmf_RM184s",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "91b75ab6-0ef3-4519-fa27-001467aaf590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68051/68051 [==============================] - 77s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat_cnn = cnn_model_loaded.predict(sequences_pad_val, batch_size=BATCH_SIZE, verbose=1)\n",
    "yhat_lr = lr_model.predict_proba(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ia7YknjQ6KZR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "y_class_cnn = (yhat_cnn > 0.5).astype('int32')\n",
    "y_class_lr = lr_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "hYbgitPK4y9G",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "bc9d2b90-b9c5-442e-f692-7683df8b63ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_roc_auc: 0.86, LR_roc_auc: 0.83\n"
     ]
    }
   ],
   "source": [
    "# roc_auc\n",
    "print(\"CNN_roc_auc: {cnn:.2f}, LR_roc_auc: {lr:.2f}\".format(cnn=roc_auc_score(y_val, yhat_cnn), lr=roc_auc_score(y_val, yhat_lr[:,1]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "98KXVV_55QWN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182.0
    },
    "outputId": "2775534b-332d-442e-f153-826b5940d610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "          pred:pos  pred:neg\n",
      "true:pos  24770     8755    \n",
      "true:neg  6716      27810   \n",
      "\n",
      "LR\n",
      "          pred:pos  pred:neg\n",
      "true:pos  24430     9095    \n",
      "true:neg  8129      26397   \n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf_matrix_cnn = confusion_matrix(y_val, y_class_cnn)\n",
    "conf_matrix_lr = confusion_matrix(y_val, y_class_lr)\n",
    "\n",
    "print(\"CNN\")\n",
    "print(pd.DataFrame(conf_matrix_cnn, index=['true:pos', 'true:neg'], columns=['pred:pos', 'pred:neg']))\n",
    "\n",
    "print(\"\\nLR\")\n",
    "print(pd.DataFrame(conf_matrix_lr, index=['true:pos', 'true:neg'], columns=['pred:pos', 'pred:neg']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XhXwItJkeD3",
    "colab_type": "text"
   },
   "source": [
    "That is, the first tweet are classified as Positive and the second as Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "tdUlF1PgkdGp",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206.0
    },
    "outputId": "694caa79-10fe-4c95-b0e0-9828ce1db646"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130831</th>\n",
       "      <td>0.585968</td>\n",
       "      <td>0.564431</td>\n",
       "      <td>седовласый инженер сказал, что удары током это вовсе не удары током, а всего лишь статика, и \"купи серебряные наручники, я тебя заземлю\".\\n:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>0.337828</td>\n",
       "      <td>0.337672</td>\n",
       "      <td>rt @dance_with_me_: кто бы знал как я не люблю безхарактерных, вечноноющих парней :-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>0.914562</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>ну всё понятно, городской житель, к ухабам и колеям не привык)) в колее то хорошо - нашел желобок - и как трамвай едешь)))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210</th>\n",
       "      <td>0.946806</td>\n",
       "      <td>0.947246</td>\n",
       "      <td>rt @nina_one_nina: @directioner6901 талдна) спасибо щедрый человек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193285</th>\n",
       "      <td>0.039314</td>\n",
       "      <td>0.107516</td>\n",
       "      <td>@advakhova  прости (( \\nвеселье уедет в раменское не честно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CNN        LR  \\\n",
       "130831  0.585968  0.564431   \n",
       "2532    0.337828  0.337672   \n",
       "31387   0.914562  0.840336   \n",
       "20210   0.946806  0.947246   \n",
       "193285  0.039314  0.107516   \n",
       "\n",
       "                                                                                                                                                tweet  \n",
       "130831  седовласый инженер сказал, что удары током это вовсе не удары током, а всего лишь статика, и \"купи серебряные наручники, я тебя заземлю\".\\n:(  \n",
       "2532    rt @dance_with_me_: кто бы знал как я не люблю безхарактерных, вечноноющих парней :-)                                                          \n",
       "31387   ну всё понятно, городской житель, к ухабам и колеям не привык)) в колее то хорошо - нашел желобок - и как трамвай едешь)))                     \n",
       "20210   rt @nina_one_nina: @directioner6901 талдна) спасибо щедрый человек                                                                             \n",
       "193285  @advakhova  прости (( \\nвеселье уедет в раменское не честно                                                                                    "
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame({\"tweet\": text_val, \"CNN\": yhat_cnn[:,0], \"LR\": yhat_lr[:,1]}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "JK32Qo61j9er",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770.0
    },
    "outputId": "cda4c7c9-18fc-453b-858b-f431ac58f064"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02271716, -0.03282207, -0.01942212, -0.06260538, -0.02711385,\n",
       "       -0.01694492, -0.00113889, -0.1432817 , -0.02591053,  0.00694427,\n",
       "       -0.00456908, -0.072645  , -0.02462506, -0.05915061,  0.01752759,\n",
       "       -0.0563279 , -0.03050778, -0.03511775,  0.00021002, -0.05763318,\n",
       "        0.04794497,  0.02431646, -0.03907726, -0.01259894,  0.01502478,\n",
       "       -0.02743094,  0.01916009,  0.02461171, -0.00249929, -0.008789  ,\n",
       "       -0.00715822, -0.04765795, -0.05609009, -0.00240624,  0.03763028,\n",
       "       -0.00055717, -0.0277299 ,  0.05324748, -0.00399163, -0.0204413 ,\n",
       "        0.03093167,  0.00538668, -0.0503009 ,  0.01336168,  0.01986855,\n",
       "        0.0211968 , -0.06580566,  0.02032636, -0.00210202,  0.03620323,\n",
       "       -0.02590587,  0.04238628, -0.07325724, -0.04166886,  0.03910806,\n",
       "       -0.00201675,  0.04281683,  0.045309  , -0.01104105, -0.00518672,\n",
       "        0.07085174,  0.0420563 ,  0.02910163, -0.01480897, -0.00597519,\n",
       "        0.02139434, -0.02614024,  0.00137777, -0.00439095, -0.07545023,\n",
       "        0.03397009, -0.0585175 ,  0.03997544, -0.06093492,  0.00188935,\n",
       "       -0.05312679, -0.04153325,  0.013458  , -0.04634466, -0.03374435,\n",
       "       -0.00784724, -0.02682424,  0.00813918, -0.02565075, -0.00869885,\n",
       "        0.04960641, -0.12892106, -0.0586089 , -0.05314058, -0.04502677,\n",
       "       -0.00828397, -0.09694147, -0.03204994, -0.07513097, -0.04792515,\n",
       "       -0.00748163,  0.00447365,  0.0091839 , -0.03664913,  0.04105171,\n",
       "       -0.04669502, -0.02198982,  0.03208548,  0.00453046,  0.00116659,\n",
       "       -0.00989856,  0.03650874, -0.00533526, -0.0816165 , -0.0133711 ,\n",
       "       -0.08718953, -0.03674372,  0.02073454, -0.00898976,  0.07207634,\n",
       "       -0.02436104, -0.00997809,  0.09793233,  0.00095233,  0.01707612,\n",
       "       -0.06466935,  0.00669122, -0.04161857, -0.07087111,  0.01466352,\n",
       "       -0.04269875, -0.02739345, -0.03823149,  0.06069191,  0.05080993,\n",
       "        0.01739024,  0.04820975,  0.00186995, -0.02202377,  0.02542489,\n",
       "       -0.02667467,  0.00032125, -0.02052291, -0.01929852,  0.007001  ,\n",
       "        0.04688952,  0.04816389,  0.00294916,  0.04090274, -0.03030103,\n",
       "        0.01767295,  0.00869443, -0.02230204,  0.03809964, -0.03216437,\n",
       "        0.07445446,  0.01771417, -0.00223139,  0.00650258,  0.03431726,\n",
       "       -0.00837597, -0.0232706 ,  0.01586384,  0.02875251,  0.00593466,\n",
       "        0.00026018,  0.01474632, -0.04845236,  0.00257329,  0.029851  ,\n",
       "        0.03963571, -0.02937507,  0.05578006,  0.00564875,  0.01738183,\n",
       "        0.00046488, -0.01196187,  0.07382622, -0.02909883, -0.02346674,\n",
       "        0.01770952,  0.00330564,  0.08348881, -0.07785255, -0.00703785,\n",
       "        0.05197482, -0.02433762, -0.02251267, -0.05155929,  0.00761709,\n",
       "        0.00857317, -0.05611515, -0.01803315, -0.06130144,  0.08755714,\n",
       "        0.02102803, -0.04196585,  0.00930537, -0.00567634,  0.01038632,\n",
       "        0.02041427, -0.0236607 , -0.03333787,  0.05335149, -0.0767115 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word embeddings\n",
    "conv_embds = cnn_model_loaded.layers[1].get_weights()[0]\n",
    "conv_embds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vjcck_Cmyh5o",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# TODO: What words have the maximum impact\n",
    "# TODO: Compare two models\n",
    "# TODO: Word embedding visualization"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment-analysis-of-tweets-in-russian.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
